{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Data Science , nous réfléchissons souvent à la manière d'utiliser les données pour faire des prédictions sur de nouvelles de données. C'est ce qu'on appelle «l'apprentissage supervisé». Parfois, plutôt que de «faire des prédictions», nous souhaitons plutôt classer les données dans des compartiments. Ceci est appelé «apprentissage non supervisé».\n",
    "\n",
    "Pour illustrer la différence, disons que nous sommes dans une grande chaîne de pizzas et que nous avons été chargés de créer une fonctionnalité dans le logiciel de gestion des commandes qui prédira les délais de livraison pour les clients. Pour ce faire, nous recevons un ensemble de données contenant les délais de livraison, les distances parcourues, le jour de la semaine, l'heure de la journée, le personnel disponible et le volume des ventes pour plusieurs livraisons dans le passé. À partir de ces données, nous pouvons faire des prévisions sur les délais de livraison futurs. Ceci est un bon exemple d'apprentissage supervisé.\n",
    "\n",
    "Désormais, disons que la chaîne de pizzas souhaite envoyer des coupons ciblés aux clients. Il souhaite segmenter ses clients en 4 groupes: familles nombreuses, petites familles, célibataires et étudiants. Nous recevons des données de commande préalables (par exemple, la taille de la commande, le prix, la fréquence, etc.) et nous sommes chargés de placer chaque client dans l'un des quatre groupes. Ce serait un exemple d '«apprentissage non supervisé» puisque nous ne faisons pas de prédictions; nous catégorisons simplement les clients en groupes.\n",
    "\n",
    "\n",
    "<!--\n",
    "*    Affinity Propagation\n",
    "*    Agglomerative Clustering\n",
    "*    BIRCH\n",
    "*    DBSCAN\n",
    "*    K-Means\n",
    "*    Mini-Batch K-Means\n",
    "*    Mean Shift\n",
    "*    OPTICS\n",
    "*    Spectral Clustering\n",
    "*    Mixture of Gaussians\n",
    "-->\n",
    "Nous allons voir dans ce cours l'algorithme des _K-means_ qui  est l'un des algos les plus utilisés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--L'algorithme $K$-means divise un ensemble de $N$ échantillons $X$ en $K$ clusters disjoints $C$, chacun étant décrit par la moyenne $\\mu_j$ des échantillons du cluster. Les moyens sont communément appelés les «centroïdes» de cluster; notez qu'ils ne sont pas, en général, des points de $X$, bien qu'ils vivent dans le même espace. L'algorithme $K$-means vise à choisir des centres de gravité qui minimisent l'inertie, ou somme intra-cluster du critère au carré:\n",
    "$$\\sum_{i=0}^n min_{\\mu_j\\in c}(|| x_j - \\mu_i||^2)$$\n",
    "\n",
    "\n",
    "**Comment fonctionne l'algorithme**\n",
    "\n",
    "L'algorithme de clustering-means utilise un raffinement itératif pour produire un résultat final. Les entrées de l'algorithme sont le nombre de clusters $ Κ $ et l'ensemble de données. L'ensemble de données est un ensemble d'entités pour chaque point de données. Les algorithmes commencent par des estimations initiales pour les centroïdes $Κ$, qui peuvent être générés aléatoirement ou sélectionnés au hasard dans l'ensemble de données. L'algorithme effectue ensuite une itération entre deux étapes:\n",
    "\n",
    "**Étape d'assignation des données**: chaque centroïde définit l'un des clusters. Dans cette étape, chaque point de données est affecté à son centre de gravité le plus proche, en fonction de la distance euclidienne au carré. Plus formellement, si $c_i$ est la collection de centroïdes dans l'ensemble $C$, alors chaque point de données $x$ est affecté à un cluster basé sur\n",
    "\n",
    "$$argmin_{c_i \\in c} dist(c_i,x)^2$$\n",
    "\n",
    "où *dist(·)* est la distance euclidienne standard ( $L_2$). Soit $S_i$ l'ensemble des affectations de points de données pour chaque ième centre de gravité du cluster.\n",
    "\n",
    "**Étape de mise à jour du centre de gravité**: dans cette étape, les centres de gravité sont recalculés. Cela se fait en prenant la moyenne de tous les points de données affectés au cluster de ce centre de gravité.\n",
    "$$c_i = \\frac{1}{[S_i|}\\sum_{x_i \\in S_i}x_i$$\n",
    "\n",
    "\n",
    "L'algorithme itère entre les étapes un et deux jusqu'à ce qu'un critère d'arrêt soit satisfait (c'est-à-dire qu'aucun point de données ne change de grappes, la somme des distances est minimisée ou un certain nombre maximal d'itérations est atteint).\n",
    "\n",
    "**Convergence et initialisation aléatoire**\n",
    "\n",
    "Cet algorithme est garanti pour converger vers un résultat. Le résultat peut être un optimum local (c'est-à-dire pas nécessairement le meilleur résultat possible), ce qui signifie que l'évaluation de plus d'une exécution de l'algorithme avec des centroïdes de départ aléatoires peut donner un meilleur résultat.\n",
    "-->\n",
    "\n",
    "<img src = \"images/kmeans.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe différentes fonctions à l'aide desquelles nous pouvons évaluer les performances des algorithmes de clustering.\n",
    "Voici quelques fonctions importantes et principalement utilisées fournies par Scikit-learn pour évaluer les performances de clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Rand Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rand Index est une fonction qui calcule une mesure de similarité entre deux regroupements. Pour ce calcul, Rand Index considère toutes les paires d'échantillons et les paires de comptage qui sont attribuées dans les clusters similaires ou différents dans le clustering prédit et vrai. Ensuite, le score brut de Rand Index est «ajusté en fonction du hasard» dans le score de Rand Index ajusté en utilisant la formule suivante:\n",
    "\n",
    "$$AdjustedRI = (RI-ExpectedRI)/(max(RI)-ExpectedRI)$$\n",
    "\n",
    "Il a deux paramètres à savoir **labels_true**, qui sont des étiquettes des **ground truth** classe, et **labels_pred**, qui sont des étiquettes de clusters à évaluer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction Silhouette calculera le coefficient de silhouette moyen de tous les échantillons en utilisant la distance moyenne intra-cluster et la distance moyenne du cluster le plus proche pour chaque échantillon.\n",
    "$$S = (b-a)/max(a,b)$$\n",
    "\n",
    "Ici, **a** est la distance intra-cluster.\n",
    "\n",
    "et **b** est la distance moyenne du groupe le plus proche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de contingence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette matrice indiquera la cardinalité d'intersection pour chaque paire de confiance de (vrai, prédit). La matrice de confusion pour les problèmes de classification est une matrice de contingence carrée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fowlkes-Mallows Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction Fowlkes-Mallows mesure la similitude de deux regroupements d'un ensemble de points. Elle peut être définie comme la moyenne géométrique de la précision et du rappel par paires.\n",
    "\n",
    "Mathématiquement\n",
    "\n",
    "$$FMS = \\frac{TP}{\\sqrt{(TP+FP)(TP+FN)}}$$\n",
    "\n",
    "Ici, **TP = True Positive** - nombre de paires de points appartenant aux mêmes clusters en vrai ainsi que les étiquettes prédites à la fois.\n",
    "\n",
    "**FP = False Positive** - nombre de paires de points appartenant aux mêmes clusters dans les étiquettes vraies mais pas dans les étiquettes prédites.\n",
    "\n",
    "**FN = False Negative** - nombre de paires de points appartenant aux mêmes clusters dans les étiquettes prédites mais pas dans les vraies étiquettes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "Voyons comment fonctionne le clustering _k-means_. Nous allons utiliser Blobby, plus exactement la fonction **make_blobs** dans la bibliothèque d'apprentissage **_sci-kit_**. Nous allons créer quatre clusters aléatoires à l'aide de **_make_blobs_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme **k-means** recherche un nombre prédéterminé de clusters dans un ensemble de données multidimensionnel non étiqueté. Il accomplit cela en utilisant une conception simple de ce à quoi ressemble le clustering optimal:\n",
    "\n",
    "*     Le «centre du cluster» est la moyenne arithmétique de tous les points appartenant au cluster.\n",
    "*     Chaque point est plus proche de son propre centre de cluster que des autres centres de cluster.\n",
    "\n",
    "Ces deux hypothèses sont à la base du modèle des k-means. Nous allons bientôt nous plonger dans la manière exacte dont l'algorithme atteint cette solution, mais pour l'instant, jetons un coup d'œil à un jeu de données simple et voyons le résultat k-means.\n",
    "\n",
    "Tout d'abord, générons un jeu de données bidimensionnel contenant quatre blobs distincts. Pour souligner qu'il s'agit d'un algorithme non supervisé, nous allons laisser les étiquettes en dehors de la visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.datasets.samples_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8632\\3635197058.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcluster_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.datasets.samples_generator'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs \n",
    "X,y_true = make_blobs(n_samples=500, centers=4,  cluster_std=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8632\\3777217377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1],s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À l'œil nu, il est relativement facile de repérer les quatre groupes. L'algorithme **k-means** le fait automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8632\\855933821.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=4)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8632\\2207599544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = km.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons les résultats en traçant les données colorées par ces étiquettes. Nous allons également tracer les centres de cluster tels que déterminés par l'estimateur **k-means**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1],s=50, c=y_pred,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "adjusted_rand_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
